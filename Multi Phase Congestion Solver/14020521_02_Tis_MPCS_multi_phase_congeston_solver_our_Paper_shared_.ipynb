{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# load file"
      ],
      "metadata": {
        "id": "HlJiNma-5_iQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz-jH8T_Uk2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "12fd5550-972b-4cfd-fdc6-23d4459ed76a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-54e51f78-7a36-4c72-bdc2-c5413b24666e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-54e51f78-7a36-4c72-bdc2-c5413b24666e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dir_G.gml to Dir_G.gml\n",
            "User uploaded file \"Dir_G.gml\" with length 942 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TmJwIYUp6LG",
        "outputId": "54e941ae-7f1a-4258-d0c8-4d978e8e0ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n"
      ],
      "metadata": {
        "id": "XIg6bvJGmqCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/My_paper/Dir_G.gml\""
      ],
      "metadata": {
        "id": "SaZN1M8_Yx7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"Dir_G.gml\""
      ],
      "metadata": {
        "id": "PF8C1r4sY7rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# Load the graph from GML file\n",
        "graph = nx.read_gml(file_path)\n"
      ],
      "metadata": {
        "id": "rvGy8a-0ZkcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Edit Graph"
      ],
      "metadata": {
        "id": "uYhHqB9HZl2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# Load the graph from GML file\n",
        "graph_ed = nx.read_gml(file_path)\n",
        "\n",
        "# Add a new node\n",
        "#graph_ed.add_node(\"new_node\")\n",
        "\n",
        "# Add a new edge\n",
        "graph_ed.add_edge(\"H1\", \"S4\")\n",
        "\n",
        "# Save the updated graph\n",
        "nx.write_gml(graph_ed, \"updated_graph.gml\")"
      ],
      "metadata": {
        "id": "JCL5X3zyZLsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = nx.read_gml(\"updated_graph.gml\")"
      ],
      "metadata": {
        "id": "MEGG_DSDZTVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Last Version"
      ],
      "metadata": {
        "id": "jwIwDk2l7b9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class documettion"
      ],
      "metadata": {
        "id": "366wjPS_sNlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "The NetworkWithDataFlow class provides functionality for managing a network graph with data flow. It allows adding nodes, modifying nodes, adding edges, and managing data flow paths within the graph. It also provides methods for saving and loading the graph structure, printing the graph structure, finding alternate paths for flows, and finding safe update paths.\n",
        "\n",
        "The class utilizes the networkx library for graph operations and pickle for serialization. The main methods and attributes of the class include:\n",
        "\n",
        "**__init__()**: Initializes the class by creating an empty directed graph, data flow list, and sets for ingress, egress, and switch nodes.\n",
        "\n",
        "**add_node(node, node_type)**: Adds a node to the graph with the specified node type (ingress, egress, or switch).\n",
        "\n",
        "**modify_node(node, node_type)**: Modifies the type of an existing node in the graph.\n",
        "\n",
        "**add_edge(source, target)**: Adds an edge between two nodes in the graph.\n",
        "\n",
        "**modify_data_flow(flow_index, new_path)**: Modifies an existing data flow path at the specified index.\n",
        "\n",
        "**add_data_flow(new_path)**: Adds a new data flow path to the graph.\n",
        "\n",
        "**save_structure(filename)**: Saves the current graph structure, ingress nodes, egress nodes, switch nodes, and data flow paths to a file using pickle.\n",
        "\n",
        "**load_structure(filename)**: Loads the graph structure, ingress nodes, egress nodes, switch nodes, and data flow paths from a file.\n",
        "\n",
        "**print_structure()**: Prints the nodes, edges, data flows, ingress nodes, egress nodes, and switch nodes of the graph.\n",
        "\n",
        "**print_alternate_paths_for_flows()**: Prints the alternate paths for each data flow in the graph.\n",
        "\n",
        "**load_graph_from_gml(filename)**: Loads the graph structure from a GML file.\n",
        "\n",
        "**save_graph_to_gml(filename)**: Saves the current graph structure to a GML file.\n",
        "\n",
        "**find_alternate_paths(path)**: Finds alternate paths for a given data flow path in the graph.\n",
        "\n",
        "**find_safe_update(flow_index)**: Finds and prints the safe update paths for a given data flow index that do not conflict with other flows.\n",
        "\n",
        "From this point on, you can continue working with the NetworkWithDataFlow class by calling its methods or implementing additional functionality as per your requirements."
      ],
      "metadata": {
        "id": "LcWWV8vpsUE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final NetworkWithDataFlow Class"
      ],
      "metadata": {
        "id": "-WohhzfvmDjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import networkx as nx\n",
        "\n",
        "class NetworkWithDataFlow:\n",
        "    def __init__(self):\n",
        "        self.graph = nx.DiGraph()\n",
        "        self.data_flow = []\n",
        "        self.ingress_nodes = set()\n",
        "        self.egress_nodes = set()\n",
        "        self.switch_nodes = set()\n",
        "\n",
        "    def add_node(self, node, node_type):\n",
        "        self.graph.add_node(node)\n",
        "        if node_type == 'ingress':\n",
        "            self.ingress_nodes.add(node)\n",
        "        elif node_type == 'egress':\n",
        "            self.egress_nodes.add(node)\n",
        "        elif node_type == 'switch':\n",
        "            self.switch_nodes.add(node)\n",
        "\n",
        "    def modify_node(self, node, node_type):\n",
        "        if node in self.graph.nodes:\n",
        "            if node_type == 'ingress':\n",
        "                self.ingress_nodes.add(node)\n",
        "                self.egress_nodes.discard(node)\n",
        "                self.switch_nodes.discard(node)\n",
        "            elif node_type == 'egress':\n",
        "                self.egress_nodes.add(node)\n",
        "                self.ingress_nodes.discard(node)\n",
        "                self.switch_nodes.discard(node)\n",
        "            elif node_type == 'switch':\n",
        "                self.switch_nodes.add(node)\n",
        "                self.ingress_nodes.discard(node)\n",
        "                self.egress_nodes.discard(node)\n",
        "        else:\n",
        "            print(f\"Node '{node}' does not exist in the graph.\")\n",
        "\n",
        "    def add_edge(self, source, target):\n",
        "        self.graph.add_edge(source, target)\n",
        "\n",
        "    def _check_conflict_between(self, path1, path2):\n",
        "        edges1 = set(zip(path1[:-1], path1[1:]))\n",
        "        edges2 = set(zip(path2[:-1], path2[1:]))\n",
        "        return bool(edges1.intersection(edges2))\n",
        "\n",
        "    def modify_data_flow(self, flow_index, new_path):\n",
        "        if flow_index < len(self.data_flow):\n",
        "            if nx.is_simple_path(self.graph, new_path):\n",
        "                if self._validate_flow_nodes(new_path):\n",
        "                    conflicting_paths = [\n",
        "                        path for i, path in enumerate(self.data_flow) if i != flow_index and self._check_conflict_between(path, new_path)\n",
        "                    ]\n",
        "                    if conflicting_paths:\n",
        "                        print(\"Conflict detected with the following paths:\")\n",
        "                        for path in conflicting_paths:\n",
        "                            print(path)\n",
        "                        print(\"Cannot modify data flow due to conflicts.\")\n",
        "                    else:\n",
        "                        self.data_flow[flow_index] = new_path\n",
        "                        print(\"Data flow modified successfully.\")\n",
        "                else:\n",
        "                    print(\"Invalid data flow path. Incorrect node types.\")\n",
        "            else:\n",
        "                print(\"Invalid data flow path. Not a simple path in the graph.\")\n",
        "        else:\n",
        "            print(\"Invalid data flow index.\")\n",
        "\n",
        "    def add_data_flow(self, new_path):\n",
        "        if nx.is_simple_path(self.graph, new_path):\n",
        "            if self._validate_flow_nodes(new_path):\n",
        "                conflicting_paths = [\n",
        "                    path for path in self.data_flow if self._check_conflict_between(path, new_path)\n",
        "                ]\n",
        "                if conflicting_paths:\n",
        "                    print(\"Conflict detected with the following paths:\")\n",
        "                    for path in conflicting_paths:\n",
        "                        print(path)\n",
        "                    print(\"Cannot add data flow due to conflicts.\")\n",
        "                else:\n",
        "                    self.data_flow.append(new_path)\n",
        "                    print(\"Data flow added successfully.\")\n",
        "            else:\n",
        "                print(\"Invalid data flow path. Incorrect node types.\")\n",
        "        else:\n",
        "            print(\"Invalid data flow path. Not a simple path in the graph.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _validate_flow_nodes(self, path):\n",
        "        if len(path) < 2:\n",
        "            return False\n",
        "\n",
        "        if path[0] not in self.ingress_nodes:\n",
        "            return False\n",
        "\n",
        "        if path[-1] not in self.egress_nodes:\n",
        "            return False\n",
        "\n",
        "        for node in path[1:-1]:\n",
        "            if node not in self.switch_nodes:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def save_structure(self, filename):\n",
        "        data = {\n",
        "            'graph': self.graph,\n",
        "            'ingress_nodes': self.ingress_nodes,\n",
        "            'egress_nodes': self.egress_nodes,\n",
        "            'switch_nodes': self.switch_nodes,\n",
        "            'data_flow': self.data_flow\n",
        "        }\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def load_structure(self, filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        self.graph = data['graph']\n",
        "        self.ingress_nodes = data['ingress_nodes']\n",
        "        self.egress_nodes = data['egress_nodes']\n",
        "        self.switch_nodes = data['switch_nodes']\n",
        "        self.data_flow = data['data_flow']\n",
        "\n",
        "    def print_structure(self):\n",
        "        print(\"nodes:\\n\", self.graph.nodes)\n",
        "        print(\"edges:\\n\", self.graph.edges)\n",
        "        print(\"flows:\\n\", self.data_flow)\n",
        "        print(\"ingress nodes:\\n\", self.ingress_nodes)\n",
        "        print(\"egress nodes:\\n\", self.egress_nodes)\n",
        "        print(\"switches:\\n\", self.switch_nodes)\n",
        "\n",
        "    def print_alternate_paths_for_flows(self):\n",
        "        for flow_index, flow_path in enumerate(self.data_flow):\n",
        "            print(f\"Flow {flow_index}:\")\n",
        "            alternate_paths = self.find_alternate_paths(flow_path)\n",
        "            for alt_path in alternate_paths:\n",
        "                print(alt_path)\n",
        "            print()\n",
        "\n",
        "    def load_graph_from_gml(self, filename):\n",
        "        self.graph = nx.read_gml(filename)\n",
        "\n",
        "    def save_graph_to_gml(self, filename):\n",
        "        nx.write_gml(self.graph, filename)\n",
        "\n",
        "    def find_alternate_paths(self, path):\n",
        "        source = path[0]\n",
        "        destination = path[-1]\n",
        "        paths = list(nx.all_simple_paths(self.graph, source=source, target=destination))\n",
        "        alternate_paths = [p for p in paths if p != path]\n",
        "        return alternate_paths\n",
        "\n",
        "\n",
        "    def find_safe_update(self, flow_index):\n",
        "        # First, find an alternate path for the given flow_index\n",
        "        flow_path = self.data_flow[flow_index]\n",
        "        alternate_paths = self.find_alternate_paths(flow_path)\n",
        "        print(f\"Alternate paths for flow {flow_index}: {flow_path}\\n\")\n",
        "        for path in alternate_paths:\n",
        "            print(path)\n",
        "        print()\n",
        "\n",
        "        # Second, find and print the safe update paths that do not conflict with other flows\n",
        "        safe_update_paths = []\n",
        "        for i, path in enumerate(alternate_paths):\n",
        "            conflicting_paths = [f for j, f in enumerate(self.data_flow) if j != flow_index and self._check_conflict_between(f, path)]\n",
        "            if not conflicting_paths:\n",
        "                safe_update_paths.append(path)\n",
        "\n",
        "        print(\"Safe update paths:\")\n",
        "        for path in safe_update_paths:\n",
        "            print(path)\n",
        "        print()\n",
        "\n",
        "        return safe_update_paths"
      ],
      "metadata": {
        "id": "91_J_NjzB20N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load graph and flows\n",
        "\n"
      ],
      "metadata": {
        "id": "Vi_SS-jfmNGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "network = NetworkWithDataFlow()\n",
        "\n",
        "# Load the graph from a GML file\n",
        "network.load_graph_from_gml('/content/drive/MyDrive/My_paper/Dir_G.gml')\n",
        "\n",
        "\n",
        "\n",
        "# it is nessesary to modiify node as {ingress, egress and switch}\n",
        "# because when you want to add flow it will check first node be ingress and last node egress\n",
        "# Modify the type of nodes\n",
        "network.modify_node('H1', 'ingress')\n",
        "\n",
        "network.modify_node('S1', 'switch')\n",
        "network.modify_node('S2', 'switch')\n",
        "network.modify_node('S3', 'switch')\n",
        "network.modify_node('S4', 'switch')\n",
        "network.modify_node('S5', 'switch')\n",
        "network.modify_node('S6', 'switch')\n",
        "\n",
        "network.modify_node('H2', 'egress')\n",
        "network.modify_node('H3', 'egress')\n",
        "\n",
        "\n",
        "# Add a data flow path\n",
        "network.add_data_flow(['H1', 'S2', 'S5', 'H3'])\n",
        "network.add_data_flow(['H1', 'S3', 'S6', 'H3'])\n",
        "network.add_data_flow(['H1', 'S1', 'S4', 'H2'])\n",
        "\n",
        "#deleberatly add some fake flow to check validity\n",
        "network.add_data_flow([ 'S3', 'S6', 'H3']) # ingress\n",
        "network.add_data_flow(['H1', 'S3', 'S6']) # egress\n",
        "network.add_data_flow(['H1', 'S1', 'H3']) # has not path\n",
        "\n",
        "# Access the loaded data\n",
        "network.print_structure()\n",
        "\n",
        "path = ['H1', 'S1', 'S4', 'H3'] # Replace with the actual path you want to find alternate paths for\n",
        "alternate_paths = network.find_alternate_paths(path)\n",
        "print(\"Alternate Paths:\")\n",
        "for alt_path in alternate_paths:\n",
        "    print(alt_path)\n",
        "\n",
        "network.print_alternate_paths_for_flows()\n",
        "\n",
        "# Save the network structure\n",
        "network.save_structure('/content/drive/MyDrive/My_paper/net_fromFilePlusflows.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQGEBYxAacQ4",
        "outputId": "1cdaed9d-e150-4092-e760-19e4ad2edfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data flow added successfully.\n",
            "Data flow added successfully.\n",
            "Data flow added successfully.\n",
            "Invalid data flow path. Incorrect node types.\n",
            "Invalid data flow path. Incorrect node types.\n",
            "Invalid data flow path. Not a simple path in the graph.\n",
            "nodes:\n",
            " ['H1', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'H2', 'H3']\n",
            "edges:\n",
            " [('H1', 'S1'), ('H1', 'S2'), ('H1', 'S3'), ('S1', 'S4'), ('S1', 'S5'), ('S2', 'S1'), ('S2', 'S5'), ('S2', 'S6'), ('S3', 'S5'), ('S3', 'S6'), ('S4', 'H2'), ('S4', 'H3'), ('S5', 'H2'), ('S5', 'H3'), ('S6', 'H3')]\n",
            "flows:\n",
            " [['H1', 'S2', 'S5', 'H3'], ['H1', 'S3', 'S6', 'H3'], ['H1', 'S1', 'S4', 'H2']]\n",
            "ingress nodes:\n",
            " {'H1'}\n",
            "egress nodes:\n",
            " {'H3', 'H2'}\n",
            "switches:\n",
            " {'S1', 'S3', 'S6', 'S2', 'S4', 'S5'}\n",
            "Alternate Paths:\n",
            "['H1', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S1', 'S4', 'H3']\n",
            "['H1', 'S2', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S5', 'H3']\n",
            "['H1', 'S2', 'S6', 'H3']\n",
            "['H1', 'S3', 'S5', 'H3']\n",
            "['H1', 'S3', 'S6', 'H3']\n",
            "Flow 0:\n",
            "['H1', 'S1', 'S4', 'H3']\n",
            "['H1', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S1', 'S4', 'H3']\n",
            "['H1', 'S2', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S6', 'H3']\n",
            "['H1', 'S3', 'S5', 'H3']\n",
            "['H1', 'S3', 'S6', 'H3']\n",
            "\n",
            "Flow 1:\n",
            "['H1', 'S1', 'S4', 'H3']\n",
            "['H1', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S1', 'S4', 'H3']\n",
            "['H1', 'S2', 'S1', 'S5', 'H3']\n",
            "['H1', 'S2', 'S5', 'H3']\n",
            "['H1', 'S2', 'S6', 'H3']\n",
            "['H1', 'S3', 'S5', 'H3']\n",
            "\n",
            "Flow 2:\n",
            "['H1', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S1', 'S4', 'H2']\n",
            "['H1', 'S2', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S5', 'H2']\n",
            "['H1', 'S3', 'S5', 'H2']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example usage: use this class for find safe route for f3\n",
        "find_safe_update = first find a alternate path of one flow in data_flow for example data_flow[2]\n",
        "and second find and print whichone have not confilict with other flows in data_flow (name it Safe_updat_paths )\n",
        "and third modify it to Safe_updat_paths[0] if exsist"
      ],
      "metadata": {
        "id": "stqTpyqR9PPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flow_index = 2\n",
        "safe_update_candidates_f3 = network.find_safe_update(flow_index)\n",
        "\n",
        "# Third, modify the path to the first safe update path that has no conflicts\n",
        "if safe_update_candidates_f3:\n",
        "    for new_route in safe_update_candidates_f3:\n",
        "        network.modify_data_flow(flow_index, new_route)\n",
        "        print(f\"Modified flow {flow_index} with a safe update path: {new_route}\")\n",
        "    else:\n",
        "        print(f\"No safe update paths without conflicts found for flow {flow_index}\")\n",
        "else:\n",
        "    print(\"No safe update paths found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0JhejI9OACs",
        "outputId": "d9bd594d-fe5f-4740-c0d7-0a75c5b9a0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternate paths for flow 2: ['H1', 'S1', 'S4', 'H2']\n",
            "\n",
            "['H1', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S1', 'S4', 'H2']\n",
            "['H1', 'S2', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S5', 'H2']\n",
            "['H1', 'S3', 'S5', 'H2']\n",
            "\n",
            "Safe update paths:\n",
            "['H1', 'S1', 'S5', 'H2']\n",
            "\n",
            "Data flow modified successfully.\n",
            "Modified flow 2 with a safe update path: ['H1', 'S1', 'S5', 'H2']\n",
            "No safe update paths without conflicts found for flow 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Old Temp\n"
      ],
      "metadata": {
        "id": "hBlWHPTZqH9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# First, find an alternate path for data_flow[2]\n",
        "flow_index = 2\n",
        "flow_path = network.data_flow[flow_index]\n",
        "alternate_paths = network.find_alternate_paths(flow_path)\n",
        "print(f\"Alternate paths for flow {flow_index}:\", flow_path ,\"is:\\n\")\n",
        "for path in alternate_paths:\n",
        "    print(path)\n",
        "print()\n",
        "\n",
        "# Second, find and print the safe update paths that do not conflict with other flows\n",
        "safe_update_paths = []\n",
        "for i, path in enumerate(alternate_paths):\n",
        "    conflicting_paths = [f for j, f in enumerate(network.data_flow) if j != flow_index and network._check_conflict_between(f, path)]\n",
        "    if not conflicting_paths:\n",
        "        safe_update_paths.append(path)\n",
        "\n",
        "print(\"Safe update paths:\")\n",
        "for path in safe_update_paths:\n",
        "    print(path)\n",
        "print()\n",
        "\n",
        "print(\"Safe update paths:\")\n",
        "for path in safe_update_paths:\n",
        "    print(path)\n",
        "print()\n",
        "\n",
        "# Third, modify the path to the first safe update path if it exists\n",
        "if safe_update_paths:\n",
        "    new_path = safe_update_paths[0]\n",
        "    network.modify_data_flow(flow_index, new_path)\n",
        "else:\n",
        "    print(\"No safe update paths found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfoVW1oS9OY0",
        "outputId": "facb7576-c2cc-4942-90be-388322335c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternate paths for flow 2: ['H1', 'S1', 'S5', 'H2'] is:\n",
            "\n",
            "['H1', 'S1', 'S4', 'H2']\n",
            "['H1', 'S2', 'S1', 'S4', 'H2']\n",
            "['H1', 'S2', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S5', 'H2']\n",
            "['H1', 'S3', 'S5', 'H2']\n",
            "\n",
            "Safe update paths:\n",
            "['H1', 'S1', 'S4', 'H2']\n",
            "\n",
            "Safe update paths:\n",
            "['H1', 'S1', 'S4', 'H2']\n",
            "\n",
            "Data flow modified successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flow_index = 2\n",
        "safe_update_paths_f3 = network.find_safe_update(2)\n",
        "# Third, modify the path to the first safe update path that has no conflicts\n",
        "if safe_update_paths_f3:\n",
        "    new_path = None\n",
        "    for path in safe_update_paths_f3:\n",
        "        conflicting_paths = [f for f in network.data_flow if f != path and network._check_conflict_between(f, path)]\n",
        "        if not conflicting_paths:\n",
        "            new_path = path\n",
        "            break\n",
        "\n",
        "    if new_path:\n",
        "        network.modify_data_flow(flow_index, new_path)\n",
        "        print(f\"Modified flow {flow_index} with a safe update path: {new_path}\")\n",
        "    else:\n",
        "        print(f\"No safe update paths without conflicts found for flow {flow_index}\")\n",
        "else:\n",
        "    print(\"No safe update paths found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2H-zkyflrw1",
        "outputId": "0dcf83c3-51f9-40fa-cb49-4a6e5dae029c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternate paths for flow 2: ['H1', 'S1', 'S4', 'H2']\n",
            "\n",
            "['H1', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S1', 'S4', 'H2']\n",
            "['H1', 'S2', 'S1', 'S5', 'H2']\n",
            "['H1', 'S2', 'S5', 'H2']\n",
            "['H1', 'S3', 'S5', 'H2']\n",
            "\n",
            "Safe update paths:\n",
            "['H1', 'S1', 'S5', 'H2']\n",
            "\n",
            "No safe update paths without conflicts found for flow 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.print_structure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dI7Y-51nttR",
        "outputId": "dfa63497-1a23-4e6b-c4f6-9f0000d4b5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nodes:\n",
            " ['H1', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'H2', 'H3']\n",
            "edges:\n",
            " [('H1', 'S1'), ('H1', 'S2'), ('H1', 'S3'), ('S1', 'S4'), ('S1', 'S5'), ('S2', 'S1'), ('S2', 'S5'), ('S2', 'S6'), ('S3', 'S5'), ('S3', 'S6'), ('S4', 'H2'), ('S4', 'H3'), ('S5', 'H2'), ('S5', 'H3'), ('S6', 'H3')]\n",
            "flows:\n",
            " [['H1', 'S2', 'S5', 'H3'], ['H1', 'S3', 'S6', 'H3'], ['H1', 'S1', 'S4', 'H2']]\n",
            "ingress nodes:\n",
            " {'H1'}\n",
            "egress nodes:\n",
            " {'H3', 'H2'}\n",
            "switches:\n",
            " {'S1', 'S3', 'S6', 'S2', 'S4', 'S5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third, modify the path to the first safe update path that has no conflicts\n",
        "if safe_update_paths:\n",
        "    new_path = None\n",
        "    for path in safe_update_paths:\n",
        "        conflicting_paths = [f for f in network.data_flow if f != path and network._check_conflict_between(f, path)]\n",
        "        if not conflicting_paths:\n",
        "            new_path = path\n",
        "            break\n",
        "\n",
        "    if new_path:\n",
        "        network.modify_data_flow(flow_index, new_path)\n",
        "        print(f\"Modified flow {flow_index} with a safe update path: {new_path}\")\n",
        "    else:\n",
        "        print(f\"No safe update paths without conflicts found for flow {flow_index}\")\n",
        "else:\n",
        "    print(\"No safe update paths found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxhepdIZGBxd",
        "outputId": "d661be55-a61d-431f-9e65-258789218860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data flow modified successfully.\n",
            "Modified flow 2 with a safe update path: ['H1', 'S1', 'S4', 'H2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### new temp\n"
      ],
      "metadata": {
        "id": "o3WH6TTdqXoe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6mL_SaFqbIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QbUkbauaqaVt"
      }
    }
  ]
}